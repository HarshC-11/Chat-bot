{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gpt_index\n",
      "  Downloading gpt_index-0.5.27-py3-none-any.whl (348 kB)\n",
      "     ------------------------------------ 348.4/348.4 kB 801.3 kB/s eta 0:00:00\n",
      "Collecting dataclasses-json (from gpt_index)\n",
      "  Downloading dataclasses_json-0.5.7-py3-none-any.whl (25 kB)\n",
      "Collecting langchain==0.0.142 (from gpt_index)\n",
      "  Downloading langchain-0.0.142-py3-none-any.whl (548 kB)\n",
      "     ------------------------------------ 548.8/548.8 kB 882.9 kB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from gpt_index) (1.23.5)\n",
      "Collecting tenacity<9.0.0,>=8.2.0 (from gpt_index)\n",
      "  Downloading tenacity-8.2.2-py3-none-any.whl (24 kB)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "anaconda-project 0.9.1 requires ruamel-yaml, which is not installed.\n",
      "conda-repo-cli 1.0.4 requires pathlib, which is not installed.\n",
      "spyder 4.2.5 requires pyqt5<5.13, which is not installed.\n",
      "spyder 4.2.5 requires pyqtwebengine<5.13, which is not installed.\n",
      "\n",
      "[notice] A new release of pip is available: 23.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai>=0.26.4 (from gpt_index)\n",
      "  Downloading openai-0.27.5-py3-none-any.whl (71 kB)\n",
      "     -------------------------------------- 71.6/71.6 kB 435.3 kB/s eta 0:00:00\n",
      "Requirement already satisfied: pandas in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from gpt_index) (1.2.4)\n",
      "Collecting tiktoken (from gpt_index)\n",
      "  Downloading tiktoken-0.3.3-cp38-cp38-win_amd64.whl (579 kB)\n",
      "     ------------------------------------ 579.6/579.6 kB 444.4 kB/s eta 0:00:00\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from langchain==0.0.142->gpt_index) (5.4.1)\n",
      "Requirement already satisfied: SQLAlchemy<2,>=1 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from langchain==0.0.142->gpt_index) (1.4.7)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain==0.0.142->gpt_index)\n",
      "  Downloading aiohttp-3.8.4-cp38-cp38-win_amd64.whl (324 kB)\n",
      "     ------------------------------------ 324.5/324.5 kB 628.5 kB/s eta 0:00:00\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain==0.0.142->gpt_index)\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting gptcache>=0.1.7 (from langchain==0.0.142->gpt_index)\n",
      "  Downloading gptcache-0.1.21-py3-none-any.whl (79 kB)\n",
      "     -------------------------------------- 79.6/79.6 kB 555.1 kB/s eta 0:00:00\n",
      "Collecting numexpr<3.0.0,>=2.8.4 (from langchain==0.0.142->gpt_index)\n",
      "  Downloading numexpr-2.8.4-cp38-cp38-win_amd64.whl (92 kB)\n",
      "     -------------------------------------- 92.7/92.7 kB 584.9 kB/s eta 0:00:00\n",
      "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain==0.0.142->gpt_index)\n",
      "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
      "     -------------------------------------- 90.0/90.0 kB 426.6 kB/s eta 0:00:00\n",
      "Collecting pydantic<2,>=1 (from langchain==0.0.142->gpt_index)\n",
      "  Downloading pydantic-1.10.7-cp38-cp38-win_amd64.whl (2.2 MB)\n",
      "     ---------------------------------------- 2.2/2.2 MB 627.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from langchain==0.0.142->gpt_index) (2.25.1)\n",
      "Collecting marshmallow<4.0.0,>=3.3.0 (from dataclasses-json->gpt_index)\n",
      "  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
      "     -------------------------------------- 49.1/49.1 kB 626.4 kB/s eta 0:00:00\n",
      "Collecting marshmallow-enum<2.0.0,>=1.5.1 (from dataclasses-json->gpt_index)\n",
      "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Collecting typing-inspect>=0.4.0 (from dataclasses-json->gpt_index)\n",
      "  Downloading typing_inspect-0.8.0-py3-none-any.whl (8.7 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from openai>=0.26.4->gpt_index) (4.59.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from pandas->gpt_index) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from pandas->gpt_index) (2021.1)\n",
      "Collecting regex>=2022.1.18 (from tiktoken->gpt_index)\n",
      "  Downloading regex-2023.3.23-cp38-cp38-win_amd64.whl (267 kB)\n",
      "     ------------------------------------ 267.9/267.9 kB 785.7 kB/s eta 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests<3,>=2 (from langchain==0.0.142->gpt_index)\n",
      "  Downloading requests-2.29.0-py3-none-any.whl (62 kB)\n",
      "     ---------------------------------------- 62.5/62.5 kB 1.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.142->gpt_index) (20.3.0)\n",
      "Collecting charset-normalizer<4.0,>=2.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.142->gpt_index)\n",
      "  Downloading charset_normalizer-3.1.0-cp38-cp38-win_amd64.whl (96 kB)\n",
      "     -------------------------------------- 96.4/96.4 kB 916.6 kB/s eta 0:00:00\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.142->gpt_index)\n",
      "  Downloading multidict-6.0.4-cp38-cp38-win_amd64.whl (28 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.142->gpt_index)\n",
      "  Downloading yarl-1.9.2-cp38-cp38-win_amd64.whl (61 kB)\n",
      "     -------------------------------------- 61.8/61.8 kB 818.1 kB/s eta 0:00:00\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.142->gpt_index)\n",
      "  Downloading frozenlist-1.3.3-cp38-cp38-win_amd64.whl (34 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.142->gpt_index)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: cachetools in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from gptcache>=0.1.7->langchain==0.0.142->gpt_index) (5.2.0)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json->gpt_index) (20.9)\n",
      "Collecting typing-extensions>=4.2.0 (from pydantic<2,>=1->langchain==0.0.142->gpt_index)\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->gpt_index) (1.15.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain==0.0.142->gpt_index) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain==0.0.142->gpt_index) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain==0.0.142->gpt_index) (2020.12.5)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from SQLAlchemy<2,>=1->langchain==0.0.142->gpt_index) (1.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from typing-inspect>=0.4.0->dataclasses-json->gpt_index) (0.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.3.0->dataclasses-json->gpt_index) (2.4.7)\n",
      "Installing collected packages: typing-extensions, tenacity, regex, numexpr, multidict, frozenlist, charset-normalizer, async-timeout, yarl, typing-inspect, requests, pydantic, marshmallow, aiosignal, tiktoken, openapi-schema-pydantic, marshmallow-enum, aiohttp, openai, dataclasses-json, gptcache, langchain, gpt_index\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.7.4.3\n",
      "    Uninstalling typing-extensions-3.7.4.3:\n",
      "      Successfully uninstalled typing-extensions-3.7.4.3\n",
      "  Attempting uninstall: regex\n",
      "    Found existing installation: regex 2021.4.4\n",
      "    Uninstalling regex-2021.4.4:\n",
      "      Successfully uninstalled regex-2021.4.4\n",
      "  Attempting uninstall: numexpr\n",
      "    Found existing installation: numexpr 2.7.3\n",
      "    Uninstalling numexpr-2.7.3:\n",
      "      Successfully uninstalled numexpr-2.7.3\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.25.1\n",
      "    Uninstalling requests-2.25.1:\n",
      "      Successfully uninstalled requests-2.25.1\n",
      "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 charset-normalizer-3.1.0 dataclasses-json-0.5.7 frozenlist-1.3.3 gpt_index-0.5.27 gptcache-0.1.21 langchain-0.0.142 marshmallow-3.19.0 marshmallow-enum-1.5.1 multidict-6.0.4 numexpr-2.8.4 openai-0.27.5 openapi-schema-pydantic-1.2.4 pydantic-1.10.7 regex-2023.3.23 requests-2.29.0 tenacity-8.2.2 tiktoken-0.3.3 typing-extensions-4.5.0 typing-inspect-0.8.0 yarl-1.9.2\n"
     ]
    }
   ],
   "source": [
    "%pip install gpt_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-cloud-logging\n",
      "  Downloading google_cloud_logging-3.5.0-py2.py3-none-any.whl (195 kB)\n",
      "     -------------------------------------- 195.8/195.8 kB 2.9 MB/s eta 0:00:00\n",
      "Collecting google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.33.2 (from google-cloud-logging)\n",
      "  Downloading google_api_core-2.11.0-py3-none-any.whl (120 kB)\n",
      "     -------------------------------------- 120.3/120.3 kB 3.6 MB/s eta 0:00:00\n",
      "Collecting google-cloud-appengine-logging<2.0.0dev,>=0.1.0 (from google-cloud-logging)\n",
      "  Downloading google_cloud_appengine_logging-1.3.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting google-cloud-audit-log<1.0.0dev,>=0.1.0 (from google-cloud-logging)\n",
      "  Downloading google_cloud_audit_log-0.2.5-py2.py3-none-any.whl (12 kB)\n",
      "Collecting google-cloud-core<3.0.0dev,>=2.0.0 (from google-cloud-logging)\n",
      "  Downloading google_cloud_core-2.3.2-py2.py3-none-any.whl (29 kB)\n",
      "Collecting grpc-google-iam-v1<1.0.0dev,>=0.12.4 (from google-cloud-logging)\n",
      "  Downloading grpc_google_iam_v1-0.12.6-py2.py3-none-any.whl (26 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.0 (from google-cloud-logging)\n",
      "  Downloading proto_plus-1.22.2-py3-none-any.whl (47 kB)\n",
      "     ---------------------------------------- 47.9/47.9 kB 2.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from google-cloud-logging) (4.22.1)\n",
      "Collecting googleapis-common-protos<2.0dev,>=1.56.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.33.2->google-cloud-logging)\n",
      "  Downloading googleapis_common_protos-1.59.0-py2.py3-none-any.whl (223 kB)\n",
      "     -------------------------------------- 223.6/223.6 kB 4.5 MB/s eta 0:00:00\n",
      "Collecting google-auth<3.0dev,>=2.14.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.33.2->google-cloud-logging)\n",
      "  Downloading google_auth-2.17.3-py2.py3-none-any.whl (178 kB)\n",
      "     -------------------------------------- 178.2/178.2 kB 3.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.33.2->google-cloud-logging) (2.29.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.33.2->google-cloud-logging) (1.50.0)\n",
      "Collecting grpcio-status<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.33.2->google-cloud-logging)\n",
      "  Downloading grpcio_status-1.54.0-py3-none-any.whl (5.1 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.33.2->google-cloud-logging) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.33.2->google-cloud-logging) (0.2.8)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.33.2->google-cloud-logging) (1.15.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.33.2->google-cloud-logging) (4.9)\n",
      "Collecting grpcio<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.33.2->google-cloud-logging)\n",
      "  Downloading grpcio-1.54.0-cp38-cp38-win_amd64.whl (4.1 MB)\n",
      "     ---------------------------------------- 4.1/4.1 MB 2.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.33.2->google-cloud-logging) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.33.2->google-cloud-logging) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.33.2->google-cloud-logging) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.33.2->google-cloud-logging) (2020.12.5)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.33.2->google-cloud-logging) (0.4.8)\n",
      "Installing collected packages: proto-plus, grpcio, googleapis-common-protos, grpcio-status, google-cloud-audit-log, google-auth, grpc-google-iam-v1, google-api-core, google-cloud-core, google-cloud-appengine-logging, google-cloud-logging\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.50.0\n",
      "    Uninstalling grpcio-1.50.0:\n",
      "      Successfully uninstalled grpcio-1.50.0\n",
      "  Attempting uninstall: google-auth\n",
      "    Found existing installation: google-auth 2.13.0\n",
      "    Uninstalling google-auth-2.13.0:\n",
      "      Successfully uninstalled google-auth-2.13.0\n",
      "Successfully installed google-api-core-2.11.0 google-auth-2.17.3 google-cloud-appengine-logging-1.3.0 google-cloud-audit-log-0.2.5 google-cloud-core-2.3.2 google-cloud-logging-3.5.0 googleapis-common-protos-1.59.0 grpc-google-iam-v1-0.12.6 grpcio-1.54.0 grpcio-status-1.54.0 proto-plus-1.22.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install google-cloud-logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama_index\n",
      "  Downloading llama_index-0.5.27.tar.gz (190 kB)\n",
      "     -------------------------------------- 190.6/190.6 kB 3.8 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: dataclasses_json in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from llama_index) (0.5.7)\n",
      "Requirement already satisfied: langchain==0.0.142 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from llama_index) (0.0.142)\n",
      "Requirement already satisfied: numpy in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from llama_index) (1.23.5)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from llama_index) (8.2.2)\n",
      "Requirement already satisfied: openai>=0.26.4 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from llama_index) (0.27.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from llama_index) (1.2.4)\n",
      "Collecting transformers (from llama_index)\n",
      "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
      "     ---------------------------------------- 7.0/7.0 MB 3.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from langchain==0.0.142->llama_index) (5.4.1)\n",
      "Requirement already satisfied: SQLAlchemy<2,>=1 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from langchain==0.0.142->llama_index) (1.4.7)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from langchain==0.0.142->llama_index) (3.8.4)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from langchain==0.0.142->llama_index) (4.0.2)\n",
      "Requirement already satisfied: gptcache>=0.1.7 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from langchain==0.0.142->llama_index) (0.1.21)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from langchain==0.0.142->llama_index) (2.8.4)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from langchain==0.0.142->llama_index) (1.2.4)\n",
      "Requirement already satisfied: pydantic<2,>=1 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from langchain==0.0.142->llama_index) (1.10.7)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from langchain==0.0.142->llama_index) (2.29.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from dataclasses_json->llama_index) (3.19.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from dataclasses_json->llama_index) (1.5.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from dataclasses_json->llama_index) (0.8.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from openai>=0.26.4->llama_index) (4.59.0)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from pandas->llama_index) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from pandas->llama_index) (2021.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from transformers->llama_index) (3.0.12)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0 (from transformers->llama_index)\n",
      "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
      "     -------------------------------------- 224.5/224.5 kB 3.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from transformers->llama_index) (20.9)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from transformers->llama_index) (2023.3.23)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers->llama_index)\n",
      "  Downloading tokenizers-0.13.3-cp38-cp38-win_amd64.whl (3.5 MB)\n",
      "     ---------------------------------------- 3.5/3.5 MB 3.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.142->llama_index) (20.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.142->llama_index) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.142->llama_index) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.142->llama_index) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.142->llama_index) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.142->llama_index) (1.3.1)\n",
      "Requirement already satisfied: cachetools in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from gptcache>=0.1.7->langchain==0.0.142->llama_index) (5.2.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers->llama_index) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers->llama_index) (4.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers->llama_index) (2.4.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->llama_index) (1.15.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain==0.0.142->llama_index) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain==0.0.142->llama_index) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain==0.0.142->llama_index) (2020.12.5)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from SQLAlchemy<2,>=1->langchain==0.0.142->llama_index) (1.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from typing-inspect>=0.4.0->dataclasses_json->llama_index) (0.4.3)\n",
      "Building wheels for collected packages: llama_index\n",
      "  Building wheel for llama_index (setup.py): started\n",
      "  Building wheel for llama_index (setup.py): finished with status 'done'\n",
      "  Created wheel for llama_index: filename=llama_index-0.5.27-py3-none-any.whl size=286180 sha256=fffbb9f5138f422ddab2a01cfa3fcec8e8fc47e3e9c09d80a4f6e43dd16c75aa\n",
      "  Stored in directory: c:\\users\\harsh\\appdata\\local\\pip\\cache\\wheels\\d9\\3c\\8e\\0fff6a0181d08fe52fcffb88bb7c58ace395644234d031ce41\n",
      "Successfully built llama_index\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers, llama_index\n",
      "Successfully installed huggingface-hub-0.14.1 llama_index-0.5.27 tokenizers-0.13.3 transformers-4.28.1\n"
     ]
    }
   ],
   "source": [
    "%pip install llama_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\harsh\\anaconda3\\lib\\site-packages (0.0.142)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from langchain) (5.4.1)\n",
      "Requirement already satisfied: SQLAlchemy<2,>=1 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from langchain) (1.4.7)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from langchain) (3.8.4)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from langchain) (0.5.7)\n",
      "Requirement already satisfied: gptcache>=0.1.7 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from langchain) (0.1.21)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from langchain) (2.8.4)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from langchain) (1.23.5)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from langchain) (1.2.4)\n",
      "Requirement already satisfied: pydantic<2,>=1 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from langchain) (1.10.7)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from langchain) (2.29.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (20.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.8.0)\n",
      "Requirement already satisfied: openai in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from gptcache>=0.1.7->langchain) (0.27.5)\n",
      "Requirement already satisfied: cachetools in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from gptcache>=0.1.7->langchain) (5.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2020.12.5)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from SQLAlchemy<2,>=1->langchain) (1.0.0)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (20.9)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (0.4.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from openai->gptcache>=0.1.7->langchain) (4.59.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (2.4.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_index import SimpleDirectoryReader, GPTListIndex, LLMPredictor, PromptHelper\n",
    "from langchain import OpenAI\n",
    "from llama_index import ServiceContext, GPTSimpleVectorIndex\n",
    "import sys \n",
    "import os\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"OPEN_API_KEY\"] = \"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\"\n",
    "# api_key = os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"OPEN_API_KEY\"] = input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def createVectorIndex(path):\n",
    "#     max_input = 4096\n",
    "#     tokens = 256\n",
    "#     chunk_size = 600\n",
    "#     max_chunk_overlap = 20\n",
    "\n",
    "#     prompt_helper = PromptHelper(max_input, tokens, max_chunk_overlap, chunk_size_limit = chunk_size)\n",
    "\n",
    "#     # Define Language Model\n",
    "#     llmPredictor = LLMPredictor(llm = OpenAI(openai_api_key=\"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\", temperature=0, model_name=\"gpt-3.5-turbo\", max_tokens=tokens))\n",
    "\n",
    "#     # loading the data\n",
    "#     docs = SimpleDirectoryReader(path).load_data()\n",
    "\n",
    "    \n",
    "#     service_context = ServiceContext.from_defaults(llm_predictor = llmPredictor, prompt_helper = prompt_helper)\n",
    "\n",
    "#     vectorIndex = GPTSimpleVectorIndex.from_documents(docs,service_context=service_context)\n",
    "\n",
    "#     # Vector creation\n",
    "#     # vectorIndex = GPTSimpleVectorIndex(index_struct=docs, llm_predictor = llmPredictor, prompt_helper = prompt_helper)\n",
    "#     vectorIndex.save_to_disk('vectorIndex.json')\n",
    "#     return vectorIndex\n",
    "\n",
    "def createVectorIndex(path):\n",
    "    max_input = 4096\n",
    "    tokens = 256\n",
    "    chunk_size = 600\n",
    "    max_chunk_overlap = 20\n",
    "\n",
    "    prompt_helper = PromptHelper(max_input, tokens, max_chunk_overlap, chunk_size_limit = chunk_size)\n",
    "\n",
    "    # Define Language Model\n",
    "    llmPredictor = LLMPredictor(llm = OpenAI(temperature=0, model_name=\"gpt-3.5-turbo\", max_tokens=tokens))\n",
    "    # llm_predictor = LLMPredictor(llm=OpenAI(temperature=0.5, model_name=\"text-davinci-003\", max_tokens=num_outputs))\n",
    "\n",
    "    # loading the data\n",
    "    docs = SimpleDirectoryReader(path).load_data()\n",
    "\n",
    "    \n",
    "    service_context = ServiceContext.from_defaults(llm_predictor = llmPredictor, prompt_helper = prompt_helper)\n",
    "\n",
    "    vectorIndex = GPTSimpleVectorIndex.from_documents(docs,service_context=service_context)\n",
    "\n",
    "    # Vector creation\n",
    "    # vectorIndex = GPTSimpleVectorIndex(index_struct=docs, llm_predictor = llmPredictor, prompt_helper = prompt_helper)\n",
    "    vectorIndex.save_to_disk('vectorIndex.json')\n",
    "    return vectorIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = input(\"Paste your OpenAI key here and hit enter:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Harsh\\anaconda3\\lib\\site-packages\\langchain\\llms\\openai.py:158: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "c:\\Users\\Harsh\\anaconda3\\lib\\site-packages\\langchain\\llms\\openai.py:661: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 374 tokens\n"
     ]
    }
   ],
   "source": [
    "vectorIndex = createVectorIndex('Knowledge')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answerMe(vectorIndex):\n",
    "    vIndex = GPTSimpleVectorIndex.load_from_disk(vectorIndex)\n",
    "    while True:\n",
    "        prompt = input('You: ')\n",
    "        response = vIndex.query(prompt, response_mode = \"compact\")\n",
    "        print(f\"Chatbot: {response} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 439 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 1 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "Pune Institute of Computer Technology (PICT) address: Survey No. 27, Near Trimurti Chowk Dhankwadi, Pune - 411043 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 439 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 1 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "Pune Institute of Computer Technology (PICT) address: Survey No. 27, Near Trimurti Chowk Dhankwadi, Pune - 411043 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 424 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 7 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "The email address of PICT is registrar@pict.edu. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 447 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 6 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "The mission of PICT is to be the leading and the most sought after institute of education and research in emerging engineering and technology disciplines that attract, retain and sustain gifted individuals of significant potential. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 444 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 3 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "The mission of PICT is to be the leading and the most sought after institute of education and research in emerging engineering and technology disciplines that attract, retain and sustain gifted individuals of significant potential. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 448 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 7 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "The mission of PICT is to be the leading and the most sought after institute of education and research in emerging engineering and technology disciplines that attract, retain and sustain gifted individuals of significant potential. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 442 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 8 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "The PICT College Vision is: \"Pune Institute of Computer Technology aspires to be the leader in Higher technical education and research of International repute.\" \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 440 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 7 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "The address of PICT is Survey No. 27, Near Trimurti Chowk Dhankwadi, Pune - 411043. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 432 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 8 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "The vision of PICT is to be the leader in Higher technical education and research of International repute. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 442 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 8 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "The PICT College Vision is: \"Pune Institute of Computer Technology aspires to be the leader in Higher technical education and research of International repute.\" \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 473 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 4 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "The PICT placement overview provides information about the placement opportunities available to students. It includes details about the placement process, the companies that have recruited from PICT, the average salary offered, and the placement trends. It also provides information about the placement support provided by the college, such as career guidance, internships, and workshops. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 439 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 10 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "Yes, the placement overview link of PICT is https://pict.edu/placement/index.php#overview. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 440 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 9 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "Yes, the 2022-23 placement overview can be found at https://pict.edu/placement/index.php#overview. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 452 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 7 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "The director's message can be found on the PICT College Vision page. It states: \"Pune Institute of Computer Technology aspires to be the leader in Higher technical education and research of International repute.\" \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 470 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 7 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "The departmental information for Pune Institute of Computer Technology (PICT) can be found on their website at https://pict.edu/departments/. The website lists the various departments and programs offered at PICT, including Computer Engineering, Information Technology, Electronics and Telecommunication, and Mechanical Engineering. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 430 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 9 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "The name of the PICT director is Dr. Sanjay B. Chaudhari. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 603 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 12 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "Yes, the Google Maps link for Pune Institute of Computer Technology (PICT) is https://www.google.com/maps/dir//SCTR'S+Pune+Institute+of+Computer+Technology+Survey+No.+27+Near,+Trimurti+Chowk,+Bharati+Vidyapeeth+Campus,+Dhankawadi+Pune,+Maharashtra+411043/@18.4575421,73.8508336,15z/data=!4m8!4m7!1m0!1m5!1m1!1s0x3bc2eac85230ba47:0x871eddd0a8a0a108!2m2!1d73.8508336!2d18.4575421. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 466 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 13 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "Dr. Prahlad T. Kulkarni is the Director of Pune Institute of Computer Technology (PICT). He is mentioned in the college history page on the PICT website (https://pict.edu/about_us/). \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 429 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 9 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "The director of PICT college is Dr. Sanjay B. Chaudhari. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 471 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 8 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "The First Year Engineering time table link for Pune Institute of Computer Technology (PICT) can be found here: https://pict.edu/academics/academic_calendar/academic_calendar_2020-21/BE_First_Year_2020-21.pdf \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 505 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 9 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "Yes, you can find information about First Year Engineering at Pune Institute of Computer Technology (PICT) on their website. The website provides information about the courses offered, admission process, and other related information. Additionally, you can find placement reports for the 2022-2023 academic year at https://pict.edu/placement/pdf/PR%202023%20batch-%2019_04_2023%20%20-final.pdf. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 450 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 8 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "Yes, you can find information about admission to Pune Institute of Computer Technology (PICT) on their website. You can visit https://pict.edu/admission/ for more information. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 448 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 9 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "No, I cannot give you access to the alumni portal. You will need to contact the Pune Institute of Computer Technology (PICT) directly for access to the alumni portal. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 481 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 11 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "Yes, you can find information about PICT alumni on the college website. There is a dedicated page for alumni which includes information about alumni events, alumni stories, and alumni networks. You can also find contact information for the alumni office. Additionally, you can find information about PICT alumni on social media platforms such as LinkedIn and Facebook. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 490 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 17 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "Yes, you can find information about the extra-curricular activities in PICT on the college website. The college offers a variety of extra-curricular activities such as sports, cultural activities, and student clubs. You can find more information about these activities on the college website at https://pict.edu/extra-curricular-activities/. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 499 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 9 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "The different clubs in PICT are:\n",
      "1. Robotics Club\n",
      "2. Entrepreneurship Club\n",
      "3. Literary Club\n",
      "4. Music Club\n",
      "5. Photography Club\n",
      "6. Sports Club\n",
      "7. Cultural Club\n",
      "8. Social Service Club\n",
      "9. Debate Club\n",
      "10. Quiz Club\n",
      "11. Science Club\n",
      "12. Art Club\n",
      "13. Film Club\n",
      "14. Gaming Club\n",
      "15. Adventure Club \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 497 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 11 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "The names of the clubs in PICT are:\n",
      "1. PICT Robotics Club\n",
      "2. PICT Entrepreneurship Club\n",
      "3. PICT Literary Club\n",
      "4. PICT Sports Club\n",
      "5. PICT Cultural Club\n",
      "6. PICT Photography Club\n",
      "7. PICT Debating Club\n",
      "8. PICT Music Club\n",
      "9. PICT Film Club\n",
      "10. PICT Art Club \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 470 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 9 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "The research groups in PICT can be found on the college website at https://pict.edu/research/index.php. The research groups include: Computer Science and Engineering, Electronics and Telecommunication Engineering, Information Technology, Mechanical Engineering, Civil Engineering, Applied Sciences, and Humanities. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 438 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 12 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "Unfortunately, no. Without prior knowledge, it is not possible to provide information about PCSB club in PICT. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 432 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 11 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "No, the provided context information does not include a link to PICT MIS log in. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 456 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 4 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "IEEE stands for the Institute of Electrical and Electronics Engineers, which is a professional organization dedicated to advancing technology for the benefit of humanity. It is the world's largest technical professional organization, with more than 423,000 members in over 160 countries. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 426 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 8 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "The full form of PCSB is PICT Centre for Skill Based Learning. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 425 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 8 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "The PICT MIS login is not provided in the context information given. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 439 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 7 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "The PICT vision is \"Pune Institute of Computer Technology aspires to be the leader in Higher technical education and research of International repute.\" \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 439 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 7 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "The PICT vision is \"Pune Institute of Computer Technology aspires to be the leader in Higher technical education and research of International repute.\" \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 439 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 9 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "Yes, the PICT placement overview can be found at https://pict.edu/placement/index.php#overview. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 434 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 8 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "The cut off of FE at Pune Institute of Computer Technology (PICT) is not available without prior knowledge. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 495 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 10 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "The cut off for first year engineering at Pune Institute of Computer Technology (PICT) is determined by the Maharashtra State Common Entrance Test (MHT-CET). The cut off marks for the 2021-2022 academic year can be found on the official website of the Directorate of Technical Education, Maharashtra State at https://dtemaharashtra.gov.in/mhtcet2021/. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 427 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 8 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "The director of PICT is Dr. Sanjay B. Chaudhari. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 430 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 9 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "The current director of PICT College is Dr. Sanjay B. Chaudhari. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 473 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 14 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "Dr. Prahlad T. Kulkarni is the Director of Pune Institute of Computer Technology (PICT). He is responsible for the college's vision, mission, history, and placement overview. He is also the author of the 2022-2023 placement report. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 519 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 10 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "The 2022-2023 placement report for Pune Institute of Computer Technology (PICT) can be found at the following link: https://pict.edu/placement/pdf/PR%202023%20batch-%2019_04_2023%20%20-final.pdf. This report provides an overview of the placement activities of the college, including the number of students placed, the companies that recruited, and the average salary offered. It also provides a breakdown of the placement activities by department and year. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 439 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 9 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "Scholarship information for PICT College can be found on the college's website at https://pict.edu/scholarships/. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 477 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 10 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "The different clubs in PICT college are:\n",
      "1. Robotics Club\n",
      "2. Entrepreneurship Club\n",
      "3. Literary Club\n",
      "4. Music Club\n",
      "5. Photography Club\n",
      "6. Sports Club\n",
      "7. Cultural Club\n",
      "8. Debate Club\n",
      "9. Social Service Club\n",
      "10. Science and Technology Club \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 468 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 8 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "The Addiction Even in PICT is an annual event organized by the college to provide students with an opportunity to interact with potential employers and explore job opportunities. The event is usually held in the month of April and includes a variety of activities such as career counseling, mock interviews, and workshops. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 509 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 8 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "TEDxPICT is an independently organized TED event hosted by Pune Institute of Computer Technology (PICT). It is an event that brings together inspiring speakers and thought leaders to share their ideas and experiences with the PICT community. The event is organized by a team of students and faculty members from PICT. The most recent TEDxPICT event was held in February 2021. For more information, please visit the official TEDxPICT website at https://tedxpict.com/. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 667 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 9 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "Useful links of PICT College:\n",
      "\n",
      "1. PICT College Website: https://pict.edu/\n",
      "2. PICT College Vision and Mission: https://pict.edu/about_us/\n",
      "3. PICT College Placement Overview: https://pict.edu/placement/index.php#overview\n",
      "4. PICT College 2022-2023 Placement Report: https://pict.edu/placement/pdf/PR%202023%20batch-%2019_04_2023%20%20-final.pdf\n",
      "5. PICT College Address Google Maps Link: https://www.google.com/maps/dir//SCTR'S+Pune+Institute+of+Computer+Technology+Survey+No.+27+Near,+Trimurti+Chowk,+Bharati+Vidyapeeth+Campus,+Dhankawadi+Pune,+Maharashtra+411043/@18.4575421,73.8508336,15z/data=!4m8!4m7!1m0!1m5!1m1!1s0x3bc2 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 447 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 8 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "The link to the TE time table for Pune Institute of Computer Technology (PICT) is https://pict.edu/academics/timetable/te.pdf. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 426 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 12 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "Unfortunately, PICT College does not have a LinkedIn profile. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 425 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 10 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "PICT College does not have any official social media accounts. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 501 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 10 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "The official social media accounts of PICT are:\n",
      "\n",
      "Facebook: https://www.facebook.com/PICT.Pune\n",
      "\n",
      "Twitter: https://twitter.com/PICT_Pune\n",
      "\n",
      "LinkedIn: https://www.linkedin.com/school/pune-institute-of-computer-technology/\n",
      "\n",
      "Instagram: https://www.instagram.com/pict_pune/ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 452 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 8 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "The LinkedIn page for Pune Institute of Computer Technology (PICT) can be found at https://www.linkedin.com/school/pune-institute-of-computer-technology/. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 442 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 10 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "The hostel charges of PICT are not available online. For more information, please contact the college directly at registrar@pict.edu. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 443 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 9 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "Yes, you can find hostel information for PICT on their website. You can find it under the \"Campus Life\" section of the website. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 422 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 7 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "The ISO of PICT is ISO 9001:2015. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 443 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 8 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "The hostel information for Pune Institute of Computer Technology (PICT) can be found on the college website at https://pict.edu/hostel/. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 434 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 10 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "The link to PICT MIS LOGIN is https://mis.pict.edu/login.php. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 431 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 5 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "The mis login link for Pune Institute of Computer Technology (PICT) is not provided in the context information. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 428 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 6 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "The PICT MIS login link is https://mis.pict.edu/login.php. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 425 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 8 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "The full form of PICT is Pune Institute of Computer Technology. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 415 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 4 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "I'm doing well, thank you. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 495 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 8 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "It can be difficult to feel sad, and it is important to take care of yourself. There are many things you can do to help yourself feel better. Consider talking to a trusted friend or family member, or a mental health professional if you need additional support. You can also try activities such as exercise, mindfulness, or creative activities like drawing or writing. Taking time to do something you enjoy can help you feel better. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 428 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 6 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "The Pune Institute of Computer Technology (PICT) does not have an official YouTube channel. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 493 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 9 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "The holidays for PICT are listed on the college's website. The academic calendar for the 2022-2023 academic year can be found here: https://pict.edu/academic_calendar/pdf/Academic%20Calendar%202022-2023.pdf. The calendar lists all the holidays for the academic year, including national holidays, college holidays, and other special days. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 452 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 10 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "The university (SPPU) rank holders can be found in the 2022-2023 placement report provided in the context information. The report contains a list of the top rank holders from the university. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 417 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 3 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "PICT stands for Pune Institute of Computer Technology. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 452 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 7 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "University rank holders of PICT can be found in the 2022-2023 placement report provided in the context information. The report contains a list of students who achieved university ranks in the academic year 2022-2023. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 441 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 10 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "The link to the university rank holders of PICT can be found here: https://pict.edu/rank_holders/index.php \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 462 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 11 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "The PICT staff of Information Technology can be found on the PICT website at https://pict.edu/it/faculty.php. The page lists the faculty members of the Information Technology department, their qualifications, and contact information. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 439 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 9 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "The Head of the IT Department at Pune Institute of Computer Technology (PICT) is Dr. P. S. Patil. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 419 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 5 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "PICT stands for Pune Institute of Computer Technology. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 429 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 11 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: \n",
      "Jayashree Jagadale is not mentioned in the context information provided. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai:error_code=None error_message=\"[''] is not valid under any of the given schemas - 'input'\" error_param=None error_type=invalid_request_error message='OpenAI API error received' stream_error=False\n",
      "INFO:openai:error_code=None error_message=\"[''] is not valid under any of the given schemas - 'input'\" error_param=None error_type=invalid_request_error message='OpenAI API error received' stream_error=False\n",
      "INFO:openai:error_code=None error_message=\"[''] is not valid under any of the given schemas - 'input'\" error_param=None error_type=invalid_request_error message='OpenAI API error received' stream_error=False\n",
      "INFO:openai:error_code=None error_message=\"[''] is not valid under any of the given schemas - 'input'\" error_param=None error_type=invalid_request_error message='OpenAI API error received' stream_error=False\n",
      "INFO:openai:error_code=None error_message=\"[''] is not valid under any of the given schemas - 'input'\" error_param=None error_type=invalid_request_error message='OpenAI API error received' stream_error=False\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-f235576c8f9d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0manswerMe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'vectorIndex.json'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-48a5058f2a6b>\u001b[0m in \u001b[0;36manswerMe\u001b[1;34m(vectorIndex)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mprompt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'You: '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvIndex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"compact\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Chatbot: {response} \\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Harsh\\anaconda3\\lib\\site-packages\\llama_index\\indices\\base.py\u001b[0m in \u001b[0;36mquery\u001b[1;34m(self, query_str, mode, query_transform, use_async, **query_kwargs)\u001b[0m\n\u001b[0;32m    258\u001b[0m             \u001b[0muse_async\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_async\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m         )\n\u001b[1;32m--> 260\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mquery_runner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m     async def aquery(\n",
      "\u001b[1;32mc:\\Users\\Harsh\\anaconda3\\lib\\site-packages\\llama_index\\indices\\query\\query_runner.py\u001b[0m in \u001b[0;36mquery\u001b[1;34m(self, query_str_or_bundle, index_id, level)\u001b[0m\n\u001b[0;32m    347\u001b[0m             \u001b[0mquery_str_or_bundle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m         )\n\u001b[1;32m--> 349\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mquery_combiner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery_bundle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m     async def aquery(\n",
      "\u001b[1;32mc:\\Users\\Harsh\\anaconda3\\lib\\site-packages\\llama_index\\indices\\query\\query_combiner\\base.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, query_bundle, level)\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;34m\"\"\"Run query combiner.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0mupdated_query_bundle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prepare_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery_bundle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         return self._query_runner.query_transformed(\n\u001b[0m\u001b[0;32m     69\u001b[0m             \u001b[0mupdated_query_bundle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_index_struct\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         )\n",
      "\u001b[1;32mc:\\Users\\Harsh\\anaconda3\\lib\\site-packages\\llama_index\\indices\\query\\query_runner.py\u001b[0m in \u001b[0;36mquery_transformed\u001b[1;34m(self, query_bundle, index_struct, level)\u001b[0m\n\u001b[0;32m    207\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mquery_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery_bundle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m     def _fetch_recursive_nodes(\n",
      "\u001b[1;32mc:\\Users\\Harsh\\anaconda3\\lib\\site-packages\\llama_index\\token_counter\\token_counter.py\u001b[0m in \u001b[0;36mwrapped_llm_predict\u001b[1;34m(_self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapped_llm_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_self\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mwrapper_logic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_self\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m                 \u001b[0mf_return_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_self\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mf_return_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Harsh\\anaconda3\\lib\\site-packages\\llama_index\\indices\\query\\base.py\u001b[0m in \u001b[0;36mquery\u001b[1;34m(self, query_bundle)\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[1;34m\"\"\"Answer a query.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[1;31m# TODO: support include summary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m         \u001b[0mnodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery_bundle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msynthesize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery_bundle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Harsh\\anaconda3\\lib\\site-packages\\llama_index\\indices\\query\\base.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self, query_bundle)\u001b[0m\n\u001b[0;32m    164\u001b[0m         \"\"\"\n\u001b[0;32m    165\u001b[0m         \u001b[0msimilarity_tracker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSimilarityTracker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[0mnodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery_bundle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msimilarity_tracker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msimilarity_tracker\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         postprocess_info = {\n",
      "\u001b[1;32mc:\\Users\\Harsh\\anaconda3\\lib\\site-packages\\llama_index\\indices\\vector_store\\base_query.py\u001b[0m in \u001b[0;36m_retrieve\u001b[1;34m(self, query_bundle, similarity_tracker)\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mquery_bundle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m                 query_bundle.embedding = (\n\u001b[1;32m---> 62\u001b[1;33m                     self._service_context.embed_model.get_agg_embedding_from_queries(\n\u001b[0m\u001b[0;32m     63\u001b[0m                         \u001b[0mquery_bundle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_strs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                     )\n",
      "\u001b[1;32mc:\\Users\\Harsh\\anaconda3\\lib\\site-packages\\llama_index\\embeddings\\base.py\u001b[0m in \u001b[0;36mget_agg_embedding_from_queries\u001b[1;34m(self, queries, agg_fn)\u001b[0m\n\u001b[0;32m     81\u001b[0m     ) -> List[float]:\n\u001b[0;32m     82\u001b[0m         \u001b[1;34m\"\"\"Get aggregated embedding from multiple queries.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[0mquery_embeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_query_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mquery\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mqueries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m         \u001b[0magg_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magg_fn\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mmean_agg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0magg_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery_embeddings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Harsh\\anaconda3\\lib\\site-packages\\llama_index\\embeddings\\base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     81\u001b[0m     ) -> List[float]:\n\u001b[0;32m     82\u001b[0m         \u001b[1;34m\"\"\"Get aggregated embedding from multiple queries.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[0mquery_embeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_query_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mquery\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mqueries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m         \u001b[0magg_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magg_fn\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mmean_agg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0magg_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery_embeddings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Harsh\\anaconda3\\lib\\site-packages\\llama_index\\embeddings\\base.py\u001b[0m in \u001b[0;36mget_query_embedding\u001b[1;34m(self, query)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_query_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;34m\"\"\"Get query embedding.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[0mquery_embedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_query_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m         \u001b[0mquery_tokens_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_total_tokens_used\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mquery_tokens_count\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Harsh\\anaconda3\\lib\\site-packages\\llama_index\\embeddings\\openai.py\u001b[0m in \u001b[0;36m_get_query_embedding\u001b[1;34m(self, query)\u001b[0m\n\u001b[0;32m    221\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Invalid mode, model combination: {key}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m             \u001b[0mengine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_QUERY_MODE_MODEL_DICT\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mget_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_text_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Harsh\\anaconda3\\lib\\site-packages\\tenacity\\__init__.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;33m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapped_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mretry_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mWrappedFn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Harsh\\anaconda3\\lib\\site-packages\\tenacity\\__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDoSleep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m                 \u001b[0mretry_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_for_next_attempt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mdo\u001b[0m  \u001b[1;31m# type: ignore[no-any-return]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Harsh\\anaconda3\\lib\\site-packages\\tenacity\\nap.py\u001b[0m in \u001b[0;36msleep\u001b[1;34m(seconds)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mThis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmay\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mmocked\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0munit\u001b[0m \u001b[0mtesting\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \"\"\"\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseconds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "answerMe('vectorIndex.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
